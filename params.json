{"name":"DAPD1DatasetsDatabase","tagline":"Build and maintain the database for the DAP-DataONE Server","body":"# Welcome to the DAP-DataONE server database documentation\r\nThe DAP-DataONE server is an implementation of a DataONE version 1, tier 1 Member Node. It is designed to act as a kind of broker for DataONE clients and data served using OPeNDAP. The server itself can be found in the project [DAPD1Servlet](https://github.com/opendap/DAPD1Servelt). This project has the code that is used to build, edit and access the database of DAP datasets used by that servlet. The DAP-DataONE sever uses the DatasetsDatabase to hold information each DAP dataset that the server makes available to DataONE clients. The servlet uses information stored in the database to build responses to the various DataONE API calls.\r\n\r\nThis project is a dependency of the [DAPD1Servlet](ttps://github.com/opendap/DAPD1Servlet) project.\r\n\r\n## What's here in the documentation?\r\nThe documentation contains information about how to:\r\n* Build the software from source\r\n* Testing the software\r\n* Serving your own data\r\n\r\nIn addition, there is documentation that discusses ways the server could be made more powerful and limitations imposed by the designs of DAP2 and DataONE:\r\n* How it works\r\n* Optimizations and Improvements\r\n\r\n## Beta software; What we assume\r\nThis is beta software without a polished build/install process. We assume you are computer savvy and know how to configure systems, install software, write shell scripts ... all that stuff. If you want to use this software but are unfamiliar with these kinds of things, contact us at support@opendap.org or [DataONE:Contact](https://www.dataone.org/contact).\r\n\r\n## Build the software\r\nThis project and its companion, DAPD1Servlet, use Maven. Because this project is required by the DAPD1Servlet, if you've followed the build instructions there, you have already built this project. If that's the case, skip down to the section on Testing or on Serving you own data.\r\n\r\n### Get Maven if you do not already have it\r\nGoto http://maven.apache.org/download.cgi, get the binary and install it. On a Mac OSX machine, put the `apache-maven-<ver>` directory in `/Applications`. Then add\r\n* export M2_HOME=/Applications/apache-maven-3.1.1\r\n* export PATH=$PATH:$M2_HOME/bin\r\nto `.bashrc` or the equivalent. `mvn --version` should work and return the expected info. \r\n\r\n### Build the code\r\nUse git to `clone` the project ([DAPD1DatasetsDatabase](https://github.com/opendap/DAPD1DatasetsDatabase)) and build it using `mvn clean install`. This will build the executable jar file used by the edit-db.sh bash shell script and install that in the local maven repository so it can be found by the DAPD1Servlet build. \r\n\r\nNote:\r\n> I use Eclipse with the Maven plugin ([m2e](http://download.eclipse.org/technology/m2e/releases)). Once the code is checked out using `git clone` on the command line, use `Eclipse:File:Import...` and choose `Git->Existing` local repository and select \r\nthe `import as general > project` option. In the project, Right click on the `pox.xml` file and choose `Run As...` to build. It would also work to check out the code directly into Eclipse.\r\n\r\n### Testing the software\r\nThe software includes som limited unit tests that will run as part of the maven build, so if the build worked, those passed. This project comes with a test database - one of the advantages of SQLite is that the database files can be moved from machine to machine and still work. To test that the software is working, use the command line tool `edit-db.sh` to dump the database contents: `./edit-db.sh -d test.db`. You should see quite a bit of output:\r\n```\r\n[nori:DAPD1DatasetsDatabase jimg$] ./edit-db.sh -d test.db\r\n21:46:05.458 [main] DEBUG o.o.d1.DatasetsDatabase.EditDatasets - Starting debug logging\r\nDatabase Name: test.db\r\n21:46:05.633 [main] DEBUG o.o.d.D.DatasetsDatabase - Opened database successfully (test.db).\r\nMetadata:\r\nId = test.opendap.org/dataone_sdo_1/opendap/hyrax/data/nc/fnoc1.nc\r\nDate = 2014-07-25T22:26:33.607+00:00\r\nFormatId = netcdf\r\nSize = 24096\r\nChecksum = 1d3afb4218605ca39a16e6fc5ffdfe1544b1dd0a\r\nAlgorithm = SHA-1\r\n.\r\n.\r\n.\r\nSMO_Id = test.opendap.org/dataone_smo_1/opendap/hyrax/data/nc/fnoc1.nc\r\n\r\nId = test.opendap.org/dataone_ore_1/opendap/hyrax/data/nc/coads_climatology.nc\r\nSDO_Id = test.opendap.org/dataone_sdo_1/opendap/hyrax/data/nc/coads_climatology.nc\r\nSMO_Id = test.opendap.org/dataone_smo_1/opendap/hyrax/data/nc/coads_climatology.nc\r\n\r\nObsoletes:\r\n[nori:DAPD1DatasetsDatabase jimg$]\r\n```\r\n\r\n### Serving your own data\r\nServing your own data means building a database of datasets using the `edit-db.sh` tool. Instead of overwriting the `test.db` database, make a new one. The `test.db` database is used by the unit tests - those tests depend on its contents. The `edit-db.sh` tool has online help (-h). Here's a list of its options and how you can use them to build up the database.\r\n\r\nThe `edit-db.sh` command always takes the name of a database file. To initialize a new database, use the `-i` option as in: `./edit-db.sh -i -d my_datasets.db`. Note that if you want to erase a database and start over you'll have to delete it using the shell; if you use `-i` with a database that already exists, you'll get an error.\r\n\r\nOK, now with the database initialized, you can use `-a` to add a dataset like this: `./edit-db.sh -a http://.../fnoc1.nc my_datasets.db`. You always need to include the database name; the argument to `-a` is DAP URL to the dataset. One of the ideas behind DataONE is that datasets can have versions. The database supports this idea by storing a serial number for each version of each dataset. You can edit the database to update the URL for a given dataset using the `-u` option like this: `./edit-db.sh -u http://.../fnoc1.nc my_datasets.db`. This will read new metadata for the URL, bump up the serial number and mark the new information as superseding the old information (DataONE uses the words *obsoletes* and *obsoletedBy*). If the URL itself has changes, use the `-o` option to provide the URL that is being obsoleted by the new URL (the argument to `-u`). Like this: `./edit-db.sh -u http://.../fnoc2.nc -o http://.../fnoc1.nc my_datasets.db`.\r\n\r\nAt any time `./edit-db.sh -d my_datasets.db` will show you the contents of the database.\r\n\r\nYou can guess that entering each URL by hand could get fairly tiring... but there's an easier way. Use the `-r` option to read a list of URLs from a file or from standard input. Put the DAP URLs in a file, one per line and use `./edit-db.sh -r datasets.txt my_datasets.db` (note that there's a file called `dataset.txt` in this project and the `test.db` database can be (re)built using it). The input to `-r` makes some assumptions about what you want to do. If the URL is already in the databse, it will assume you want to update it (`-u`); if it's not in the database, it will assume you want to add (`-a`) it; and if two URLs are given on a line it assumes the first URL should update the second - as if you used `-u <first URL> -o <second URL>`. Also note that -r will read from standard input if `-` is used as the file name.\r\n\r\n## About the design, potential optimizations and its current limitations\r\nThis tool, the functions that access the database and the database itself are pretty basic. Information about each dataset is held in six tables in the database. Most of the code that accesses the database is part of this project, shielding the DAPD1Servlet from the actual database structure.\r\n\r\n### How it works\r\n*I'm going to assume you know how DataONE works, at least at a basic level.*\r\n\r\nFor each DAP dataset, there is a single 'base URL' that is used to access both the Science Data Object (SDO) and Science Metadata Object (SMO). The URLs that will return those are built by appending a particular suffix to the base URL. Thus, for each DAP dataset, there is a 'base URL' and two derived URLs. Furthermore, DataONE uses Persistent Identifiers (PIDs) to refer to the SDO, SMO and ORE documents. The PIDs are send to the DataONE server as an argument of the 'object' function and the DataONE server returns the correct thing. Because of this, we must map those PIDs to the URLs that can be used to access the SDO and SMO from the DAP server. The ORE document, as explained in the DAPD1Servlet documentation, is stored in the database; more on that in a bit.\r\n\r\n![The Database Tables](/database_tables.pdf)\r\n\r\n## Optimizations and Improvements\r\nBecause the project also contains code that will be used by the servlet to read from the database, all of the accesses use the JDBC PreparedStatement object. PreparedStatements are precompiled by the underlying JDBC driver and then parameters, if there are any, are substituted as a separate post-compilation step. This prevents SQL injection attacks - an issue with any web interface that uses a database. One optimization would involve reorganizing these PreparedStatements and the objects that used them to minimize the number of times the database is asked to compile them, maximizing the number of times that same objects can be reused.\r\n\r\nThe database tables are, I think, at least third normal form and so it is possible to use the SQL JOIN command efficiently to replace multiple queries with a single access to two or more JOINed tables.\r\n\r\nIt would be much nicer to have a GUI of some sort (a web interface?) that would provide a more interactive want to look at the database contents and update the datasets. At the same time, if the SMO responses were stored in the database this UI could be used to edit/augment the information in those responses. This could improve the performance of the DataONE catalog search functions implemented by the Coordinating Nodes.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}